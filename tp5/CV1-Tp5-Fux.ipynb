{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visión por Computadora 1\n",
    "## TP 5 \n",
    "## Alumno: Santiago Fux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si queremos que las imágenes sean mostradas en una ventana emergente quitar el inline\n",
    "%matplotlib inline\n",
    "\n",
    "# OpenCV-Python utiliza NumPy para el manejo de imágenes\n",
    "import numpy as np\n",
    "# cv2 es el módulo python para acceder a OpenCV \n",
    "import cv2 as cv\n",
    "# Usamos las poderosas herramientas de graficación de matplotlib para mostrar imágenes, perfiles, histogramas, etc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementar el detector de fondo naive usando la mediana como estimador. El algoritmo debe recibir el parámetro N (cantidad de frames utilizados para la estimación) y el intervalo de tiempo para recalcular el fondo.\n",
    "* Se deben generar las mascaras de foreground y aplicarlas a los frames\n",
    "para segmentar los objetos en movimiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(images):\n",
    "  m = np.median(images, axis = 0)\n",
    "  return m.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(cap, n):\n",
    "  #obtengo total de frames\n",
    "  total = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "  # verifico max\n",
    "  if n > total:\n",
    "    n = total\n",
    "  # obtengo índices random\n",
    "  idxs = np.random.randint(total, size=(n))\n",
    "  return idxs\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(cap, idxs):\n",
    "  res = []\n",
    "  # save last position\n",
    "  curr_frame = cap.get(1) # cv.CV_CAP_PROP_POS_FRAMES\n",
    "  for i in idxs:\n",
    "    cap.set(1, i) # cv.CV_CAP_PROP_POS_FRAMES\n",
    "    ret, frame = cap.read()\n",
    "    res.append(frame)\n",
    "  # restore frame\n",
    "  cap.set(1, curr_frame) # cv.CV_CAP_PROP_POS_FRAMES\n",
    "  res = np.array(res).astype('uint8')\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts():\n",
    "  return np.uint32(datetime.timestamp(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bg_sub(cap, n, interval, level):\n",
    "  # obtengo muestras aleatorias\n",
    "  exit = False\n",
    "  next_recalc_ts = 0\n",
    "  frame_rate = cap.get(5) # cv.CV_CAP_PROP_FPS\n",
    "\n",
    "  naive_process_times = []\n",
    "  naive_bg_recalculations = []\n",
    "  while exit == False:\n",
    "    # obtengo ts actual\n",
    "    now = get_ts()\n",
    "    if now > next_recalc_ts:      \n",
    "      ti = cv.getTickCount()\n",
    "      # obtengo indices de los frames\n",
    "      mean_idxs = get_random_samples(cap, n)\n",
    "      # genero vector con las imagenes(cap) \n",
    "      mean_vector = get_mean_vector(cap, mean_idxs)\n",
    "      # recalculo media de los frames\n",
    "      mean_img = calculate_median(mean_vector)\n",
    "      # Aplicar el filtro de mediana\n",
    "      mean_img = cv.medianBlur(mean_img, 5)\n",
    "      # reinicio contador\n",
    "      next_recalc_ts = now + interval\n",
    "      tf = cv.getTickCount()\n",
    "      diff_ms = np.uint32((tf-ti) * 1000)/ cv.getTickFrequency()\n",
    "      naive_bg_recalculations.append(diff_ms)\n",
    "    \n",
    "    #obtengo imagen\n",
    "    success, img = cap.read()\n",
    "\n",
    "    if success:\n",
    "      #guardo tiempo inicial\n",
    "      ti = cv.getTickCount()\n",
    "      # hago substraccion de fondo conservando el valor absoluto por si el foreground es más oscuro\n",
    "      diff_img = cv.absdiff(img, mean_img)\n",
    "      # Extra: Convierto a escala de grises y luego replico la misma para todos los canales\n",
    "      diff_img = cv.cvtColor(diff_img, cv.COLOR_BGR2GRAY)\n",
    "      diff_img = cv.merge([diff_img, diff_img, diff_img])\n",
    "      # binarizo\n",
    "      _, diff_img = cv.threshold(diff_img, level, 255,cv.THRESH_BINARY)\n",
    "\n",
    "      # obtengo las mascaras\n",
    "      fg_masked = cv.bitwise_and(img, cv.bitwise_not(diff_img))\n",
    "      bg_masked = cv.bitwise_and(mean_img, diff_img)\n",
    "      # obtengo la imagen final con sólo el background\n",
    "      bg_img = cv.add(fg_masked, bg_masked)\n",
    "\n",
    "      # muestro imagen de la máscara\n",
    "      cv.imshow(f'original', img)\n",
    "      cv.imshow(f'background only', bg_img)\n",
    "      cv.imshow(f'mask', diff_img)\n",
    "      diff_ms = np.uint32((tf-ti) * 1000)/ cv.getTickFrequency()\n",
    "      # print(f'tiempo demandado:{diff_ms}')\n",
    "      naive_process_times.append(diff_ms)\n",
    "    else:\n",
    "      print(f'Error leyendo video....')\n",
    "      exit = True\n",
    "\n",
    "    # verifico si tengo que terminar\n",
    "    key = cv.waitKey(np.uint32(1000/frame_rate - diff_ms)) & 0xFF\n",
    "    #cv.destroyAllWindows()\n",
    "    if key == ord(\"q\"):\n",
    "      exit = True\n",
    "\n",
    "  if len(naive_process_times) > 0:\n",
    "    naive_process_time = np.mean(naive_process_times)\n",
    "    print(f'naive process time (mean)={naive_process_time}')\n",
    "    naive_bg_recalculation = np.mean(naive_bg_recalculations)\n",
    "    print(f'naive recalculation time (mean)={naive_bg_recalculation}')    \n",
    "  cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive process time (mean)=2.088825993344538\n",
      "naive recalculation time (mean)=2.306293195692308\n"
     ]
    }
   ],
   "source": [
    "#procesamos el archivo de gente caminando y pasamos un umbral\n",
    "n = 10\n",
    "interval = 5\n",
    "level = 80\n",
    "filename = 'vtest.avi'\n",
    "#inicio captura\n",
    "capture = cv.VideoCapture(filename)\n",
    "#disparo procesamiento\n",
    "naive_bg_sub(capture, n, interval, level)\n",
    "#detengo captura\n",
    "capture.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error leyendo video....\n",
      "naive process time (mean)=2.069264603921225\n",
      "naive recalculation time (mean)=2.7060300297142854\n"
     ]
    }
   ],
   "source": [
    "# procesamos video de autos\n",
    "n = 10\n",
    "interval = 5\n",
    "level = 10\n",
    "filename = 'slow_traffic_small.mp4'\n",
    "#inicio captura\n",
    "capture = cv.VideoCapture(filename)\n",
    "#disparo procesamiento\n",
    "naive_bg_sub(capture, n, interval, level)\n",
    "#detengo captura\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparar con alguno de los métodos vistos en la practica basados en\n",
    "mezcla de gaussianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mog2_bg_sub(cap):\n",
    "    # elegimos el método MOG2 para hacer substracción\n",
    "    backSub = cv.createBackgroundSubtractorMOG2()\n",
    "    # guardamos los valores de procesamiento\n",
    "    mog2_process_times = []\n",
    "    # Corremos la sustraccion\n",
    "    #------------------------\n",
    "    while True:\n",
    "        # Leemos un frame\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        \n",
    "        ti = cv.getTickCount()\n",
    "\n",
    "        # Aplicamos la sustracción al frame leído\n",
    "        #----------------------------------------\n",
    "        # Cada frame se utiliza tanto para calcular la máscara de primer plano como para actualizar el fondo.\n",
    "        # Si se desea cambiar la tasa de aprendizaje utilizada para actualizar el modelo de fondo, es posible\n",
    "        # establecer una tasa de aprendizaje específica pasando un parámetro al método apply.\n",
    "        fgMask = backSub.apply(frame)\n",
    "\n",
    "        tf = cv.getTickCount()\n",
    "        \n",
    "        # Escribimos sobre la imagen el número de frame procesado\n",
    "        cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "        cv.putText(frame, str(cap.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "        \n",
    "        # mostramos frame original e imagen binaria background/foreground\n",
    "        cv.imshow('original', frame)\n",
    "        cv.imshow('mask', fgMask)\n",
    "\n",
    "        diff_ms = np.uint32((tf-ti) * 1000)/ cv.getTickFrequency()\n",
    "        #print(f'tiempo demandado:{diff_ms}')\n",
    "        mog2_process_times.append(diff_ms)\n",
    "        \n",
    "        # Corresmos hasta que termine o apriete escape\n",
    "        keyboard = cv.waitKey(30)\n",
    "        if keyboard == ord(\"q\") or keyboard == 27:\n",
    "            break\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    if len(mog2_process_times) > 0:\n",
    "        mog2_process_time = np.mean(mog2_process_times)\n",
    "        print(f'mog2 process time (mean)={mog2_process_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mog2 process time (mean)=1.660285160563522\n"
     ]
    }
   ],
   "source": [
    "# ejectutamos para el video de la gente caminando\n",
    "filename = 'vtest.avi'\n",
    "capture = cv.VideoCapture(filename)\n",
    "\n",
    "#disparamos detección\n",
    "mog2_bg_sub(capture)\n",
    "capture.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mog2 process time (mean)=3.076551454380744\n"
     ]
    }
   ],
   "source": [
    "# ejectutamos para el video de los autos\n",
    "filename = 'slow_traffic_small.mp4'\n",
    "capture = cv.VideoCapture(filename)\n",
    "\n",
    "#disparamos detección\n",
    "mog2_bg_sub(capture)\n",
    "capture.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Método|Video|Tiempo procesamiento| Tiempo cálculo bg  |\n",
    "|------|-----|---------|----|\n",
    "|Naive Bg Sub|vtest.avi|2.088ms|2.306ms|\n",
    "|Naive Bg Sub|slow_traffic_small.mp4|2.069ms|2.706ms|\n",
    "|MOG2 Bg Sub|vtest.avi|1,66ms|Incluido en el tiempo de procesamiento|\n",
    "|MOG2 Bg Sub|slow_traffic_small.mp4|3,07655ms|Incluido en el tiempo de procesamiento|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Se verifica según los tiempos relevados que el procesamiento implementado con MOG2 es muy superior en tiempo dado que en el mismo tiempo que insume nuestro algoritmo para el procesamiento de una frame, el MOG2 realiza dicho procesamiento junto con el recálculo del background.  \n",
    "De todos modos en todos los casos el tiempo insumido está dentro del zócalo de tiempo mínimo necesario entre frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('vision-robotica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af437b5139b375ee3fab2b21e8a1376590e14b3c752e237587dc080bd8d5be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
